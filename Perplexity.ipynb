{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1176fff0-1496-49f6-8d37-ed3d4b7b5c80",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c18f32-3641-4fd0-880c-3650300313d6",
   "metadata": {},
   "source": [
    "## Blaise Swartwood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3badbd6-b4e7-4d62-a7d1-cd269e430902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swartwba/GPTModel/venv_tinystories/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117cbad3-2efb-46b5-a2fb-1ad7eb0c0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_PATH = \"./models/tinystories_gpt_1layer/final_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6afa72a-6c40-4e64-b36b-bb3a5c3516d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Once upon a time, in a land far away,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45085d60-f428-436a-9399-692109267b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading tokenizer and model from: ./models/tinystories_gpt_1layer/final_model\n",
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(f\"Loading tokenizer and model from: {DEFAULT_MODEL_PATH}\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL_PATH)\n",
    "    if tokenizer.pad_token is None:\n",
    "         tokenizer.pad_token = tokenizer.eos_token\n",
    "         print(f\"Set pad_token to eos_token ({tokenizer.pad_token}) after loading.\")\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained(DEFAULT_MODEL_PATH)\n",
    "    model.to(device) \n",
    "    model.eval()    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or tokenizer: {e}\")\n",
    "    print(\"Ensure the path is correct and contains the necessary files \")\n",
    "    print(\"(pytorch_model.bin, config.json, tokenizer.json, etc.)\")\n",
    "    print(\"These should be saved by train_gpt.py in the 'final_model' subdirectory.\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbb560a-1fcc-444d-8f00-0076e3ebc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(PROMPT, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4e40d6-e778-4287-8e80-0f9e7407b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(PROMPT, model, tokenizer, device):\n",
    "    inputs = tokenizer(PROMPT, return_tensors=\"pt\").to(device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    # Forward pass (with labels shifted by one position)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute perplexity\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Extract probabilities of actual next tokens\n",
    "    # Shift tokens and logits for next-token prediction\n",
    "    shifted_logits = logits[:, :-1, :]\n",
    "    shifted_labels = input_ids[:, 1:]\n",
    "\n",
    "    # Probabilities for actual tokens\n",
    "    shifted_probs = F.softmax(shifted_logits, dim=-1)\n",
    "    actual_token_probs = torch.gather(\n",
    "        shifted_probs, dim=-1, index=shifted_labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    return perplexity.item(), actual_token_probs.cpu().numpy(), input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f118d6-d001-4274-8045-ebe8c476e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swartwba/GPTModel/venv_tinystories/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Greedy:\n",
      " Once upon a time, in a land far away, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big, scary monster. The monster was very scary and Lily was scared.\n",
      "\n",
      "üîπ Sample:\n",
      " Once upon a time, in a land far away, there was a little boy named Tom. Tom loved to explore and see all the things he could find. One day, he found a big box and went inside the hunt.\n",
      "\n",
      "Tom was\n",
      "\n",
      "üîπ Top-k:\n",
      " Once upon a time, in a land far away, there lived a little girl named Lily. One day, she went to a big mountain with her mom. While they were walking, Lily saw a scary bug who was scared. She didn't like\n",
      "\n",
      "üîπ Top-p:\n",
      " Once upon a time, in a land far away, there was a nice girl named Lily. She loved to play with her toys, but one day she accidentally stepped on the walls. Her friend was upset because she was playing with her toys.\n",
      "\n",
      "\n",
      "üîπ Beam Search:\n",
      " Once upon a time, in a land far away, there was a little boy named Timmy. Timmy loved to play with his toys all day long. One day, Timmy's mom asked him to clean up his toys. Timmy didn\n"
     ]
    }
   ],
   "source": [
    "max_length = 50\n",
    "temperature = 1.0\n",
    "num_return_sequences = 1\n",
    "pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Generation loop\n",
    "with torch.no_grad():\n",
    "    # üîπ Greedy decoding\n",
    "    greedy_output = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=1.0,      # Doesn't matter for greedy (no sampling)\n",
    "        top_k=0,              # Disable top-k\n",
    "        top_p=1.0,            # Disable nucleus sampling\n",
    "        do_sample=False,      # ‚Üê Greedy decoding\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "\n",
    "    # Normal Sampling\n",
    "    sample_output = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=1.0,\n",
    "        top_k=0,             # Disable top-k sampling\n",
    "        top_p=1.0,            # Disable nucleus\n",
    "        do_sample=True,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "\n",
    "    # üîπ Top-k sampling\n",
    "    topk_output = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=1.0,\n",
    "        top_k=50,             # Enable top-k sampling\n",
    "        top_p=1.0,            # Disable nucleus\n",
    "        do_sample=True,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "\n",
    "    # üîπ Top-p (nucleus) sampling\n",
    "    topp_output = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=1.0,\n",
    "        top_k=0,              # Disable top-k\n",
    "        top_p=0.9,            # Enable top-p sampling\n",
    "        do_sample=True,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "\n",
    "    beam_output = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,            # Use beam width of 5 (can be tuned)\n",
    "        do_sample=False,        # Deterministic beam search\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=pad_token_id,\n",
    "        early_stopping=True     # Optional: stop when all beams reach EOS\n",
    "    )\n",
    "\n",
    "# Decode and print\n",
    "print(\"üîπ Greedy:\\n\", tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n",
    "print(\"üîπ Sample:\\n\", tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "print(\"\\nüîπ Top-k:\\n\", tokenizer.decode(topk_output[0], skip_special_tokens=True))\n",
    "print(\"\\nüîπ Top-p:\\n\", tokenizer.decode(topp_output[0], skip_special_tokens=True))\n",
    "print(\"\\nüîπ Beam Search:\\n\", tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1658127-5524-4b6e-ab37-d5343c94051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print(generated_output, strategy_name):\n",
    "    text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "    perplexity, token_probs, input_ids = compute_perplexity(text, model, tokenizer, device=\"cuda\")\n",
    "    tokens = input_ids[0].tolist()\n",
    "    decoded_tokens = [tokenizer.decode([tid]) for tid in tokens]\n",
    "\n",
    "    print(f\"\\nüîπ {strategy_name} Sampling\")\n",
    "    print(\"=\" * (len(strategy_name) + 12))\n",
    "    print(f\"Generated Text:\\n{text}\\n\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "    print(\"Next-token prediction probabilities:\")\n",
    "    for i, prob in enumerate(token_probs[0]):\n",
    "        prev_token = decoded_tokens[i]\n",
    "        actual_next_token = decoded_tokens[i + 1]\n",
    "        print(f\"After '{prev_token}' ‚Üí '{actual_next_token}': {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f09df7-7ad1-4628-830b-9a0b2f2ceeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Greedy Sampling\n",
      "==================\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big, scary monster. The monster was very scary and Lily was scared.\n",
      "\n",
      "\n",
      "Perplexity: 2.24\n",
      "Next-token prediction probabilities:\n",
      "After 'Once' ‚Üí ' upon': 0.8850\n",
      "After ' upon' ‚Üí ' a': 0.9836\n",
      "After ' a' ‚Üí ' time': 0.9991\n",
      "After ' time' ‚Üí ',': 0.7619\n",
      "After ',' ‚Üí ' in': 0.0043\n",
      "After ' in' ‚Üí ' a': 0.9557\n",
      "After ' a' ‚Üí ' land': 0.0046\n",
      "After ' land' ‚Üí ' far': 0.1259\n",
      "After ' far' ‚Üí ' away': 0.7399\n",
      "After ' away' ‚Üí ',': 0.0409\n",
      "After ',' ‚Üí ' there': 0.9376\n",
      "After ' there' ‚Üí ' was': 0.6122\n",
      "After ' was' ‚Üí ' a': 0.9760\n",
      "After ' a' ‚Üí ' little': 0.4792\n",
      "After ' little' ‚Üí ' girl': 0.7101\n",
      "After ' girl' ‚Üí ' named': 0.8823\n",
      "After ' named' ‚Üí ' Lily': 0.9388\n",
      "After ' Lily' ‚Üí '.': 0.9670\n",
      "After '.' ‚Üí ' She': 0.9013\n",
      "After ' She' ‚Üí ' loved': 0.8367\n",
      "After ' loved' ‚Üí ' to': 0.9095\n",
      "After ' to' ‚Üí ' play': 0.7249\n",
      "After ' play' ‚Üí ' outside': 0.4339\n",
      "After ' outside' ‚Üí ' in': 0.4937\n",
      "After ' in' ‚Üí ' the': 0.8909\n",
      "After ' the' ‚Üí ' sunshine': 0.3383\n",
      "After ' sunshine' ‚Üí '.': 0.6979\n",
      "After '.' ‚Üí ' One': 0.9747\n",
      "After ' One' ‚Üí ' day': 0.9897\n",
      "After ' day' ‚Üí ',': 0.9994\n",
      "After ',' ‚Üí ' she': 0.7562\n",
      "After ' she' ‚Üí ' saw': 0.3822\n",
      "After ' saw' ‚Üí ' a': 0.8956\n",
      "After ' a' ‚Üí ' big': 0.4090\n",
      "After ' big' ‚Üí ',': 0.1843\n",
      "After ',' ‚Üí ' scary': 0.1975\n",
      "After ' scary' ‚Üí ' monster': 0.3276\n",
      "After ' monster' ‚Üí '.': 0.2915\n",
      "After '.' ‚Üí ' The': 0.4345\n",
      "After ' The' ‚Üí ' monster': 0.9870\n",
      "After ' monster' ‚Üí ' was': 0.5181\n",
      "After ' was' ‚Üí ' very': 0.1930\n",
      "After ' very' ‚Üí ' scary': 0.3833\n",
      "After ' scary' ‚Üí ' and': 0.5972\n",
      "After ' and' ‚Üí ' Lily': 0.2413\n",
      "After ' Lily' ‚Üí ' was': 0.2724\n",
      "After ' was' ‚Üí ' scared': 0.7048\n",
      "After ' scared' ‚Üí '.': 0.6838\n",
      "After '.' ‚Üí '\n",
      "': 0.3760\n",
      "\n",
      "üîπ Sample Sampling\n",
      "==================\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away, there was a little boy named Tom. Tom loved to explore and see all the things he could find. One day, he found a big box and went inside the hunt.\n",
      "\n",
      "Tom was\n",
      "\n",
      "Perplexity: 4.48\n",
      "Next-token prediction probabilities:\n",
      "After 'Once' ‚Üí ' upon': 0.8850\n",
      "After ' upon' ‚Üí ' a': 0.9836\n",
      "After ' a' ‚Üí ' time': 0.9991\n",
      "After ' time' ‚Üí ',': 0.7619\n",
      "After ',' ‚Üí ' in': 0.0043\n",
      "After ' in' ‚Üí ' a': 0.9557\n",
      "After ' a' ‚Üí ' land': 0.0046\n",
      "After ' land' ‚Üí ' far': 0.1259\n",
      "After ' far' ‚Üí ' away': 0.7399\n",
      "After ' away' ‚Üí ',': 0.0409\n",
      "After ',' ‚Üí ' there': 0.9376\n",
      "After ' there' ‚Üí ' was': 0.6122\n",
      "After ' was' ‚Üí ' a': 0.9760\n",
      "After ' a' ‚Üí ' little': 0.4792\n",
      "After ' little' ‚Üí ' boy': 0.1997\n",
      "After ' boy' ‚Üí ' named': 0.8969\n",
      "After ' named' ‚Üí ' Tom': 0.0135\n",
      "After ' Tom' ‚Üí '.': 0.9847\n",
      "After '.' ‚Üí ' Tom': 0.9287\n",
      "After ' Tom' ‚Üí ' loved': 0.5134\n",
      "After ' loved' ‚Üí ' to': 0.9607\n",
      "After ' to' ‚Üí ' explore': 0.0350\n",
      "After ' explore' ‚Üí ' and': 0.2783\n",
      "After ' and' ‚Üí ' see': 0.0192\n",
      "After ' see' ‚Üí ' all': 0.1194\n",
      "After ' all' ‚Üí ' the': 0.7399\n",
      "After ' the' ‚Üí ' things': 0.1738\n",
      "After ' things' ‚Üí ' he': 0.3843\n",
      "After ' he' ‚Üí ' could': 0.4441\n",
      "After ' could' ‚Üí ' find': 0.4095\n",
      "After ' find' ‚Üí '.': 0.9125\n",
      "After '.' ‚Üí ' One': 0.6193\n",
      "After ' One' ‚Üí ' day': 0.9866\n",
      "After ' day' ‚Üí ',': 0.9753\n",
      "After ',' ‚Üí ' he': 0.3178\n",
      "After ' he' ‚Üí ' found': 0.2656\n",
      "After ' found' ‚Üí ' a': 0.9157\n",
      "After ' a' ‚Üí ' big': 0.2575\n",
      "After ' big' ‚Üí ' box': 0.1701\n",
      "After ' box' ‚Üí ' and': 0.0348\n",
      "After ' and' ‚Üí ' went': 0.0296\n",
      "After ' went' ‚Üí ' inside': 0.3343\n",
      "After ' inside' ‚Üí ' the': 0.0539\n",
      "After ' the' ‚Üí ' hunt': 0.0000\n",
      "After ' hunt' ‚Üí '.': 0.9183\n",
      "After '.' ‚Üí '\n",
      "': 0.3420\n",
      "After '\n",
      "' ‚Üí '\n",
      "': 0.9924\n",
      "After '\n",
      "' ‚Üí 'Tom': 0.6874\n",
      "After 'Tom' ‚Üí ' was': 0.2007\n",
      "\n",
      "üîπ Top-k Sampling\n",
      "=================\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away, there lived a little girl named Lily. One day, she went to a big mountain with her mom. While they were walking, Lily saw a scary bug who was scared. She didn't like\n",
      "\n",
      "Perplexity: 3.30\n",
      "Next-token prediction probabilities:\n",
      "After 'Once' ‚Üí ' upon': 0.8850\n",
      "After ' upon' ‚Üí ' a': 0.9836\n",
      "After ' a' ‚Üí ' time': 0.9991\n",
      "After ' time' ‚Üí ',': 0.7619\n",
      "After ',' ‚Üí ' in': 0.0043\n",
      "After ' in' ‚Üí ' a': 0.9557\n",
      "After ' a' ‚Üí ' land': 0.0046\n",
      "After ' land' ‚Üí ' far': 0.1259\n",
      "After ' far' ‚Üí ' away': 0.7399\n",
      "After ' away' ‚Üí ',': 0.0409\n",
      "After ',' ‚Üí ' there': 0.9376\n",
      "After ' there' ‚Üí ' lived': 0.3566\n",
      "After ' lived' ‚Üí ' a': 0.9638\n",
      "After ' a' ‚Üí ' little': 0.4231\n",
      "After ' little' ‚Üí ' girl': 0.6976\n",
      "After ' girl' ‚Üí ' named': 0.8474\n",
      "After ' named' ‚Üí ' Lily': 0.8880\n",
      "After ' Lily' ‚Üí '.': 0.9795\n",
      "After '.' ‚Üí ' One': 0.1163\n",
      "After ' One' ‚Üí ' day': 0.9714\n",
      "After ' day' ‚Üí ',': 0.9994\n",
      "After ',' ‚Üí ' she': 0.6503\n",
      "After ' she' ‚Üí ' went': 0.5201\n",
      "After ' went' ‚Üí ' to': 0.5998\n",
      "After ' to' ‚Üí ' a': 0.2890\n",
      "After ' a' ‚Üí ' big': 0.2159\n",
      "After ' big' ‚Üí ' mountain': 0.0273\n",
      "After ' mountain' ‚Üí ' with': 0.4096\n",
      "After ' with' ‚Üí ' her': 0.9514\n",
      "After ' her' ‚Üí ' mom': 0.8179\n",
      "After ' mom' ‚Üí '.': 0.1747\n",
      "After '.' ‚Üí ' While': 0.0467\n",
      "After ' While' ‚Üí ' they': 0.6725\n",
      "After ' they' ‚Üí ' were': 0.9675\n",
      "After ' were' ‚Üí ' walking': 0.5370\n",
      "After ' walking' ‚Üí ',': 0.9266\n",
      "After ',' ‚Üí ' Lily': 0.7859\n",
      "After ' Lily' ‚Üí ' saw': 0.8204\n",
      "After ' saw' ‚Üí ' a': 0.9471\n",
      "After ' a' ‚Üí ' scary': 0.0097\n",
      "After ' scary' ‚Üí ' bug': 0.0263\n",
      "After ' bug' ‚Üí ' who': 0.0215\n",
      "After ' who' ‚Üí ' was': 0.5220\n",
      "After ' was' ‚Üí ' scared': 0.1025\n",
      "After ' scared' ‚Üí '.': 0.6030\n",
      "After '.' ‚Üí ' She': 0.3621\n",
      "After ' She' ‚Üí ' didn': 0.1319\n",
      "After ' didn' ‚Üí ''t': 0.9987\n",
      "After ''t' ‚Üí ' like': 0.0668\n",
      "\n",
      "üîπ Top-p Sampling\n",
      "=================\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away, there was a nice girl named Lily. She loved to play with her toys, but one day she accidentally stepped on the walls. Her friend was upset because she was playing with her toys.\n",
      "\n",
      "\n",
      "Perplexity: 3.86\n",
      "Next-token prediction probabilities:\n",
      "After 'Once' ‚Üí ' upon': 0.8850\n",
      "After ' upon' ‚Üí ' a': 0.9836\n",
      "After ' a' ‚Üí ' time': 0.9991\n",
      "After ' time' ‚Üí ',': 0.7619\n",
      "After ',' ‚Üí ' in': 0.0043\n",
      "After ' in' ‚Üí ' a': 0.9557\n",
      "After ' a' ‚Üí ' land': 0.0046\n",
      "After ' land' ‚Üí ' far': 0.1259\n",
      "After ' far' ‚Üí ' away': 0.7399\n",
      "After ' away' ‚Üí ',': 0.0409\n",
      "After ',' ‚Üí ' there': 0.9376\n",
      "After ' there' ‚Üí ' was': 0.6122\n",
      "After ' was' ‚Üí ' a': 0.9760\n",
      "After ' a' ‚Üí ' nice': 0.0075\n",
      "After ' nice' ‚Üí ' girl': 0.1055\n",
      "After ' girl' ‚Üí ' named': 0.7952\n",
      "After ' named' ‚Üí ' Lily': 0.8776\n",
      "After ' Lily' ‚Üí '.': 0.9651\n",
      "After '.' ‚Üí ' She': 0.8676\n",
      "After ' She' ‚Üí ' loved': 0.8218\n",
      "After ' loved' ‚Üí ' to': 0.9156\n",
      "After ' to' ‚Üí ' play': 0.6746\n",
      "After ' play' ‚Üí ' with': 0.3710\n",
      "After ' with' ‚Üí ' her': 0.9757\n",
      "After ' her' ‚Üí ' toys': 0.7281\n",
      "After ' toys' ‚Üí ',': 0.2168\n",
      "After ',' ‚Üí ' but': 0.4601\n",
      "After ' but' ‚Üí ' one': 0.1852\n",
      "After ' one' ‚Üí ' day': 0.9691\n",
      "After ' day' ‚Üí ' she': 0.7864\n",
      "After ' she' ‚Üí ' accidentally': 0.2133\n",
      "After ' accidentally' ‚Üí ' stepped': 0.0475\n",
      "After ' stepped' ‚Üí ' on': 0.7619\n",
      "After ' on' ‚Üí ' the': 0.1349\n",
      "After ' the' ‚Üí ' walls': 0.0025\n",
      "After ' walls' ‚Üí '.': 0.6186\n",
      "After '.' ‚Üí ' Her': 0.2531\n",
      "After ' Her' ‚Üí ' friend': 0.0088\n",
      "After ' friend' ‚Üí ' was': 0.1365\n",
      "After ' was' ‚Üí ' upset': 0.1415\n",
      "After ' upset' ‚Üí ' because': 0.2929\n",
      "After ' because' ‚Üí ' she': 0.6950\n",
      "After ' she' ‚Üí ' was': 0.0658\n",
      "After ' was' ‚Üí ' playing': 0.0168\n",
      "After ' playing' ‚Üí ' with': 0.7632\n",
      "After ' with' ‚Üí ' her': 0.8345\n",
      "After ' her' ‚Üí ' toys': 0.5202\n",
      "After ' toys' ‚Üí '.': 0.3307\n",
      "After '.' ‚Üí '\n",
      "': 0.4772\n",
      "\n",
      "üîπ Beam Search Sampling\n",
      "=======================\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away, there was a little boy named Timmy. Timmy loved to play with his toys all day long. One day, Timmy's mom asked him to clean up his toys. Timmy didn\n",
      "\n",
      "Perplexity: 1.79\n",
      "Next-token prediction probabilities:\n",
      "After 'Once' ‚Üí ' upon': 0.8850\n",
      "After ' upon' ‚Üí ' a': 0.9836\n",
      "After ' a' ‚Üí ' time': 0.9991\n",
      "After ' time' ‚Üí ',': 0.7619\n",
      "After ',' ‚Üí ' in': 0.0043\n",
      "After ' in' ‚Üí ' a': 0.9557\n",
      "After ' a' ‚Üí ' land': 0.0046\n",
      "After ' land' ‚Üí ' far': 0.1259\n",
      "After ' far' ‚Üí ' away': 0.7399\n",
      "After ' away' ‚Üí ',': 0.0409\n",
      "After ',' ‚Üí ' there': 0.9376\n",
      "After ' there' ‚Üí ' was': 0.6122\n",
      "After ' was' ‚Üí ' a': 0.9760\n",
      "After ' a' ‚Üí ' little': 0.4792\n",
      "After ' little' ‚Üí ' boy': 0.1997\n",
      "After ' boy' ‚Üí ' named': 0.8969\n",
      "After ' named' ‚Üí ' Tim': 0.9369\n",
      "After ' Tim' ‚Üí 'my': 0.6224\n",
      "After 'my' ‚Üí '.': 0.9802\n",
      "After '.' ‚Üí ' Tim': 0.9644\n",
      "After ' Tim' ‚Üí 'my': 0.9864\n",
      "After 'my' ‚Üí ' loved': 0.8845\n",
      "After ' loved' ‚Üí ' to': 0.9037\n",
      "After ' to' ‚Üí ' play': 0.7984\n",
      "After ' play' ‚Üí ' with': 0.5633\n",
      "After ' with' ‚Üí ' his': 0.9630\n",
      "After ' his' ‚Üí ' toys': 0.7564\n",
      "After ' toys' ‚Üí ' all': 0.2293\n",
      "After ' all' ‚Üí ' day': 0.9745\n",
      "After ' day' ‚Üí ' long': 0.9255\n",
      "After ' long' ‚Üí '.': 0.9672\n",
      "After '.' ‚Üí ' One': 0.7462\n",
      "After ' One' ‚Üí ' day': 0.9843\n",
      "After ' day' ‚Üí ',': 0.9990\n",
      "After ',' ‚Üí ' Tim': 0.8631\n",
      "After ' Tim' ‚Üí 'my': 0.9953\n",
      "After 'my' ‚Üí ''s': 0.8338\n",
      "After ''s' ‚Üí ' mom': 0.8102\n",
      "After ' mom' ‚Üí ' asked': 0.2849\n",
      "After ' asked' ‚Üí ' him': 0.9934\n",
      "After ' him' ‚Üí ' to': 0.8731\n",
      "After ' to' ‚Üí ' clean': 0.5518\n",
      "After ' clean' ‚Üí ' up': 0.8097\n",
      "After ' up' ‚Üí ' his': 0.8016\n",
      "After ' his' ‚Üí ' toys': 0.8465\n",
      "After ' toys' ‚Üí '.': 0.4283\n",
      "After '.' ‚Üí ' Tim': 0.6612\n",
      "After ' Tim' ‚Üí 'my': 0.9989\n",
      "After 'my' ‚Üí ' didn': 0.6720\n"
     ]
    }
   ],
   "source": [
    "# Run for each\n",
    "evaluate_and_print(greedy_output, \"Greedy\")\n",
    "evaluate_and_print(sample_output, \"Sample\")\n",
    "evaluate_and_print(topk_output, \"Top-k\")\n",
    "evaluate_and_print(topp_output, \"Top-p\")\n",
    "evaluate_and_print(beam_output, \"Beam Search\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT1Layer",
   "language": "python",
   "name": "venv_tinystories"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
